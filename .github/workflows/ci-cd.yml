name: CI/CD Pipeline

on:
  push:
    branches: [ main, dev ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test-and-train:
    runs-on: ubuntu-latest
    env:
      # Use the secret for the remote MLflow tracking server URI
      MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
      # GCS bucket for storing MLflow artifacts
      MLFLOW_ARTIFACT_ROOT: "gs://mlops-course-wide-link-461605-p9-unique/mlflow-artifacts"

    permissions:
      contents: write
      pull-requests: write
      issues: write

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run data validation tests
      run: python -m pytest tests/test_data_validation.py -v

    - name: Run model evaluation tests
      run: python -m pytest tests/test_model_evaluation.py -v
      
    - name: Authenticate with GCP
      uses: google-github-actions/auth@v2
      with:
        credentials_json: '${{ secrets.GCP_SA_KEY }}'
    
    - name: Set up Google Cloud SDK
      uses: google-github-actions/setup-gcloud@v2

    - name: Setup CML
      uses: iterative/setup-cml@v1

    - name: Run ML pipeline with MLflow and generate report
      run: |
        # These scripts are now updated to handle MLflow logging
        python src/data_loader.py
        python src/train_model.py
        python src/evaluate_model.py

        # Generate the CML report markdown file
        echo "## Model Performance Report" > report.md
        echo "" >> report.md
        echo "### Training Metrics (on test split)" >> report.md
        python -c "import json; m = json.load(open('models/metrics.json')); print(f'- Accuracy: {m[\"accuracy\"]:.4f}')" >> report.md
        echo "" >> report.md
        echo "### Evaluation Metrics (on full dataset)" >> report.md
        python -c "import json; m = json.load(open('models/evaluation_metrics.json')); print(f'- Accuracy: {m[\"full_dataset_accuracy\"]:.4f}\\n- Precision: {m[\"precision\"]:.4f}\\n- Recall: {m[\"recall\"]:.4f}\\n- F1-Score: {m[\"f1_score\"]:.4f}')" >> report.md
        echo "" >> report.md
        echo "### Confusion Matrix" >> report.md
        echo '![](./models/confusion_matrix.png)' >> report.md

    - name: Create CML Comment on Pull Request
      env:
        REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        cml comment create report.md
